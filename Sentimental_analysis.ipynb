{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTROL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the set of TWEET TEXT and the STOPWORDS\n",
    "italian_tweets_text = pd.read_csv('italian_tweet_text_notusa.csv',header=None)\n",
    "stopwords = pd.read_json('stopwords-it.json')\n",
    "stopwords = stopwords[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Clean the text in a tweet by removing links and special characters using regex.\n",
    "    '''\n",
    "    tweet_nolink = re.sub(r'(\\s)https\\w+', r'', tweet.lower())\n",
    "    \n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet_nolink).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_lang=\"en\"\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "final_list= []\n",
    "\n",
    "# CHECK IF IT IS 1 THE CORRECT INDEX!! IT DEPENDS ON THE SCHEMA WE HAVE\n",
    "for tweet in italian_tweets_text[1]:\n",
    "    tweet = clean_tweet(tweet)\n",
    "    from_lang=\"it\"\n",
    "    api_url = \"http://mymemory.translated.net/api/get?q={}&langpair={}|{}\".format(tweet, from_lang, to_lang)\n",
    "    hdrs ={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "    response = requests.get(api_url, headers=hdrs)\n",
    "    response_json = json.loads(response.text)\n",
    "    translation = response_json[\"responseData\"][\"translatedText\"]\n",
    "    translator_name = \"MemoryNet Translation Service\"\n",
    "    vs = analyzer.polarity_scores(translation)\n",
    "    list_sentiment = [vs['neg'],vs['neu'],vs['pos'],vs['compound']]\n",
    "    final_list.append(list_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store in an Excel file : (INDEX,TWEET,SENTIMENT)\n",
    "df1 = pd.DataFrame(final_list, columns=['negative','neutral','positive','compound'])\n",
    "df2 = pd.DataFrame({'index':italian_tweets_text[0],\n",
    "                     'tweet':italian_tweets_text[1]})\n",
    "df3 = pd.concat([df2, df1], axis=1)\n",
    "df3.to_csv(\"Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langdetect import detect\n",
    "# Create a text file \n",
    "#def create_txt(italian_tweets_text):\n",
    "#    italian_tweets_text = italian_tweets_text[1]\n",
    "#    italian_tweet = italian_tweets_text[[detect(a)!= 'en' for a in italian_tweets_text]]\n",
    "    \n",
    "#    with open('tweet.txt', 'w') as f:\n",
    "#        [f.write(clean_tweet(tweet) +'.\\n') for tweet in italian_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_txt(italian_tweets_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tweet):\n",
    "    '''\n",
    "    Translate Italian tweets to English\n",
    "    '''\n",
    "    blob = TextBlob(tweet)\n",
    "    print(tweet)\n",
    "    print(blob.detect_language())\n",
    "    if blob.detect_language() != \"en\":\n",
    "        tweet = blob.translate(to = \"en\")\n",
    "    time.sleep(2)\n",
    "    return str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open('tweet.txt','r') \n",
    "#english = translate(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Classify the polarity of a tweet.\n",
    "    '''\n",
    "    cleaned_tweet = translate(clean_tweet(tweet))\n",
    "    analysis = TextBlob(cleaned_tweet)\n",
    "    #if analysis.sentiment.polarity > 0:\n",
    "    #    return 1\n",
    "    #elif analysis.sentiment.polarity == 0:\n",
    "    #    return 0\n",
    "    #else:\n",
    "    #    return -1\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_part_sentiment = np.array([analize_sentiment(tweet) for tweet in italian_tweets_text[1][0:8912]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'index':italian_tweets_text[0][0:17824],\n",
    "                     'tweet':italian_tweets_text[1][0:17824],\n",
    "                     'sentiment':First_part_sentiment})\n",
    "df1.to_csv(\"df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Second_part_sentiment = np.array([analize_sentiment(tweet) for tweet in italian_tweets_text[1][8913:17825]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'index':italian_tweets_text[0][17825:38629],\n",
    "                     'tweet':italian_tweets_text[1][17825:38629],\n",
    "                     'sentiment':Second_part_sentiment})\n",
    "df2.to_csv(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Third_part_sentiment = np.array([analize_sentiment(tweet) for tweet in italian_tweets_text[1][17826:28227]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'index':italian_tweets_text[0][17825:38629],\n",
    "                     'tweet':italian_tweets_text[1][17825:38629],\n",
    "                     'sentiment':Third_part_sentiment})\n",
    "df3.to_csv(\"df3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fourth_part_sentiment = np.array([analize_sentiment(tweet) for tweet in italian_tweets_text[1][28228:38629]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'index':italian_tweets_text[0][17825:38629],\n",
    "                     'tweet':italian_tweets_text[1][17825:38629],\n",
    "                     'sentiment':Fourth_part_sentiment})\n",
    "df4.to_csv(\"df4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a column with the result of the analysis:\n",
    "#italian_tweets_text['SA'] = np.array([analize_sentiment(tweet) for tweet in italian_tweets_text[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "to_lang=\"en\"\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "final_list= []\n",
    "for tweet in italian_tweets_text[1][2000:10000]:\n",
    "    from_lang=\"it\"\n",
    "    api_url = \"http://mymemory.translated.net/api/get?q={}&langpair={}|{}\".format(tweet, from_lang, to_lang)\n",
    "    hdrs ={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "    response = requests.get(api_url, headers=hdrs)\n",
    "    response_json = json.loads(response.text)\n",
    "    translation = response_json[\"responseData\"][\"translatedText\"]\n",
    "    translator_name = \"MemoryNet Translation Service\"\n",
    "    vs = analyzer.polarity_scores(translation)\n",
    "    list_sentiment = [vs['neg'],vs['neu'],vs['pos'],vs['compound']]\n",
    "    final_list.append(list_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['positive'] == 0.394]\n",
    "df2[df2['index'] == 10].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(final_list, columns=['negative','neutral','positive','compound'])\n",
    "df2 = pd.DataFrame({'index':italian_tweets_text[0][0:2000],\n",
    "                     'tweet':italian_tweets_text[1][0:2000]})\n",
    "df3 = pd.concat([df2, df1], axis=1)\n",
    "df3.to_csv(\"Part1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = [vs['neg'],vs['neu'],vs['pos'],vs['compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(tweet for tweet in ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
